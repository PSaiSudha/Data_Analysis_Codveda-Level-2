# -*- coding: utf-8 -*-
"""CodVeda Level-2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZCOFDe0J4AVRVW4meImRdMBznAdDyh6s
"""

from google.colab import files
uploaded = files.upload()
for filename in uploaded.keys():
    print(f'Uploaded {filename} ({len(uploaded[filename])} bytes)')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
column_names = [
    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'
]
df = pd.read_csv('4) house Prediction Data Set.csv', delim_whitespace=True, header=None, names=column_names)
print(df)

X = df[['RM']]
y = df['MEDV']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

intercept = model.intercept_
coefficient = model.coef_[0]
print(f"Regression Equation: MEDV = {intercept:.2f} + {coefficient:.2f} * RM")

y_pred = model.predict(X_test)

r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"\nModel Performance:")
print(f"R-squared: {r2:.4f}")
print(f"Mean Squared Error: {mse:.4f}")

plt.figure(figsize=(10, 6))
plt.scatter(X_test, y_test, color='blue', label='Actual values')
plt.plot(X_test, y_pred, color='red', linewidth=2, label='Regression line')
plt.xlabel('Average Number of Rooms (RM)')
plt.ylabel('Median Home Value ($1000s)')
plt.title('Simple Linear Regression: Rooms vs. Home Value')
plt.legend()
plt.show()

from google.colab import files
uploaded = files.upload()
for filename in uploaded.keys():
    print(f'Uploaded {filename} ({len(uploaded[filename])} bytes)')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.filters.hp_filter import hpfilter
#Load the data
df = pd.read_csv('churn-bigml-20.csv')
print(df)

df['Churn'] = df['Churn'].astype(int)
print(df['Churn'])

ts_data = df.groupby('Account length')['Churn'].mean().reset_index()
print(ts_data)

ts_data = ts_data.rename(columns={'Account length': 'Days', 'Churn': 'Churn_Rate'})
print(ts_data)

ts_data.set_index('Days', inplace=True)

plt.figure(figsize=(12, 6))
plt.plot(ts_data.index, ts_data['Churn_Rate'], label='Daily Churn Rate')
plt.title('Customer Churn Rate by Account Length (Days)')
plt.xlabel('Days as Customer')
plt.ylabel('Churn Rate')
plt.grid(True)
plt.legend()
plt.show()

cycle, trend = hpfilter(ts_data['Churn_Rate'], lamb=1600)

plt.figure(figsize=(12, 8))
plt.subplot(3, 1, 1)
plt.plot(ts_data.index, ts_data['Churn_Rate'], label='Original')
plt.title('Original Time Series')
plt.grid(True)

plt.subplot(3, 1, 2)
plt.plot(ts_data.index, trend, label='Trend', color='orange')
plt.title('Trend Component')
plt.grid(True)

plt.subplot(3, 1, 3)
plt.plot(ts_data.index, cycle, label='Cyclical', color='green')
plt.title('Cyclical Component')
plt.grid(True)

plt.tight_layout()
plt.show()

moving_avg = ts_data['Churn_Rate'].rolling(window=30).mean()
print(moving_avg)

plt.figure(figsize=(12, 6))
plt.plot(ts_data.index, ts_data['Churn_Rate'], label='Daily Churn Rate', alpha=0.5)
plt.plot(moving_avg.index, moving_avg, label='30-Day Moving Average', color='red', linewidth=2)
plt.title('Churn Rate with 30-Day Moving Average Smoothing')
plt.xlabel('Days as Customer')
plt.ylabel('Churn Rate')
plt.grid(True)
plt.legend()
plt.show()

from google.colab import files
uploaded = files.upload()
for filename in uploaded.keys():
    print(f'Uploaded {filename} ({len(uploaded[filename])} bytes)')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import seaborn as sns
#Load the dataset
data = pd.read_csv('churn-bigml-80.csv')
print(data)

data['International plan'] = data['International plan'].map({'Yes': 1, 'No': 0})
print(data['International plan'])

data['Voice mail plan'] = data['Voice mail plan'].map({'Yes': 1, 'No': 0})
print(data['Voice mail plan'])

data['Churn'] = data['Churn'].map({True: 1, False: 0})
print(data['Churn'])

features = data.drop(['State', 'Area code', 'Churn'], axis=1)
print(features)

scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
print(scaled_features)

wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(scaled_features)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss, marker='o', linestyle='--')
plt.title('Elbow Method for Optimal Number of Clusters')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS (Within-Cluster Sum of Squares)')
plt.grid()
plt.show()

optimal_clusters = 3
kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', random_state=42)
clusters = kmeans.fit_predict(scaled_features)

data['Cluster'] = clusters

pca = PCA(n_components=2)
principal_components = pca.fit_transform(scaled_features)
principal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])
principal_df['Cluster'] = clusters

plt.figure(figsize=(10, 8))
sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=principal_df, palette='viridis', s=100)
plt.title('Customer Segments (2D PCA Projection)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend(title='Cluster')
plt.grid()
plt.show()

cluster_analysis = data.groupby('Cluster')[['Total day minutes', 'Total eve minutes', 'Total night minutes',  'International plan', 'Customer service calls', 'Churn']].mean()
print("\nCluster Characteristics:")
print(cluster_analysis)

plt.figure(figsize=(15, 10))

plt.subplot(2, 2, 1)
sns.boxplot(x='Cluster', y='Total day minutes', data=data)
plt.title('Daytime Minutes by Cluster')

plt.subplot(2, 2, 2)
sns.boxplot(x='Cluster', y='Total eve minutes', data=data)
plt.title('Evening Minutes by Cluster')

plt.subplot(2, 2, 3)
sns.boxplot(x='Cluster', y='Total night minutes', data=data)
plt.title('Night Minutes by Cluster')

plt.subplot(2, 2, 4)
sns.countplot(x='Cluster', hue='Churn', data=data)
plt.title('Churn Distribution by Cluster')

plt.tight_layout()
plt.show()